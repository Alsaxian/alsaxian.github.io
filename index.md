## Welcome to Xian's Resume Homepage!

  This is `Xian`, A committed _Cloud Architect_, _Senior Cloud Engineer_, _ML and Data DevOps_, graph database designer, Kubernetes enthusiast, Java, Scala, Python and .NET developer with 8 yoe that helps companies build Cloud and on-premises platforms, CI/CD-ize product mature ML models, a team player with proven interpersonal skills, a solution-focused person who is also interested by consulting and sales engineering.  
  
  Currently located in Stuttgart, he also fancies the good weather of the French Côte d'Azur, the Dutch cheese and the traditional little towns of the Alpen countries. He's _open to new professional opprtunities_ including permanent roles and freelance contracts across Western and Central Europe. Employers, HRs and job agencies are therefore welcome to reach out by droping him a line via [xian.yang@hueninger.com](mailto:xian.yang@hueninger.com) or [ring him](+33695634584).  
  
  Speaks fluent German, French, English and Chinese.

### Xian's career interest

#### Where he is now
Building AI friendly enterprise platforms in the Cloud for companies' and end users' projects.
#### Where he is going
Making everything "_cloudy_" and serverless and becoming a Lead Cloud Engineer / Senior Cloud Architect.
```sh
docker run -d --name=xianinaction --hostname=yesheis --publish=7474:7474 --publish=7687:7687 --volume=$HOME/pathtoyourheart/import:/import \ 
  --volume=$HOME/pathtoyourheart/data:/data --volume=$HOME/pathtoyourheart/plugins:/plugins --volume=$HOME/pathtoyourheart/conf:/conf --env NEO4JLABS_PLUGINS='[\"apoc\"]' \
  -e NEO4J_apoc_export_file_enabled=true -e NEO4J_apoc_import_file_enabled=true -e NEO4J_apoc_import_file_use__neo4j__config=true -e NEO4J_dbms_security_procedures_unrestricted=apoc.\* --env NEO4J_dbms_memory_pagecache_size=4G --env NEO4J_dbms_memory_heap_max__size=8G --env NEO4J_AUTH=neo4j/youllneverknowxianspassword --env NEO4J_ACCEPT_LICENSE_AGREEMENT=yes  --env NEO4J_dbms_connector_https_advertised__address="localhost:7473" --env NEO4J_dbms_connector_http_advertised__address="localhost:7474"  --env NEO4J_dbms_connector_bolt_advertised__address="localhost:7687" \
  neo4j:enterprise
``` 
### Xian's favourite
```json
{
    "work related":
    {
        "subject": ["graph theory", "multi.cloud"],
        "topic": ["Spark structured streaming", "write('once').deploy('everywhere')"],
        "IDE": "VS Code",
        "cloud platform": "Azure",
        "Kubernetes tool": "Helm",
        "database": ["Tigergraph", "Cassandra", "Elasticsearch", "Redis"],
        "language": 
        {
            "OOP": "C#", 
            "FP": "Scala", 
            "data analytics": "R"
        },
        "team spirit": 100
    },
    "life related":
    {
        "language": "Alsatian",
        "city": ["Strasbourg", "Freiburg", "Leipzig", "Basel"],
        "holiday": "beach",
        "hotel": "Trivago",
        "open-minded": true
    }        
}
```
### Other things he knows
```markdown
`Docker`, `Kubernetes`, `Kafka`, `Git`, `SQL`-dialects, `Java`, `machine learning`, `statistics`, `make sushis` and many more.
```

### Xian's background

12. __Clod Engineer and Lead Data Engineer__
  - April - December 2023, _Adevinta ASA_, Germany
  - In my role as Lead Data Engineer, I led a team of specialists in the development and implementation of data warehouses and streaming services on the Google Cloud Platform (GCP) and AWS, as part of a strategic multi-cloud initiative. My leadership approach focused on inspiring and guiding the team to realize Kafka and Spark streaming services to meet the growing demands of real-time data processing for e-commerce businesses. I fostered a culture of collaboration and innovation, leading to the development of a powerful multi-cloud platform specifically designed to meet the needs of stakeholders as well as data analysts and data scientists. Emphasizing data privacy and security, I developed an IoC-based access management system for secure and efficient data transfer. Tools: Jira, Trello, Miro, Kafka, Spark, GCP, BigQuery, Dataproc, Cloud Functions, Pub/Sub, Cloud Scheduler, Looker, AWS, IAM and Policy, Role Assuming, SQS, Terraform, Terragrunt.

11. __Cloud DevOps Engineer__
  - November 2022 – March 2023, _Edeka Digital GmbH_, Germany
  - In this project, I played a key role in coordinating cloud migration projects and was deeply involved in Scrum methodologies. I advised and supported development teams in all Azure-related topics, particularly in implementing services like serverless computing with Azure Functions and ensuring network efficiency and security. Tools: Jira/Confluence, Azure, Terraform, Github Actions, Docker, Datadog.
  
10. __Senior Consultant__
  - July - October 2022, _Centa MG GmbH_, Germany
  - As a Senior Consultant at Centa MG GmbH, I led a team for a short-term project and advised the client on data architecture and strategy. My primary focus was on migrating enterprise data to the cloud, including building a data warehouse in AWS and developing automated pipelines with AWS Glue and Terraform for efficient data processing and transfer. Tools: Jira/Confluence, AWS EMR, AWS Glue, Terraform, Spark, Docker.

9. __Cloud Engineer__
  - September 2021 - July 2022, _Mercedes Benz Tech Innovation GmbH_, Germany
  - In order to migrate a classical machine learning model to Azure, which aims to predict the vehicle repair rate, I interpreted the Python project into Spark and used Databricks, MLflow and Azure Data Factory to automate the data ingestion and to parallelize the model training. Front-end data visualization uses Grafana. Tools: Azure Data Factory, Databricks, Spark, Delta Lake, data vault, Azure Pipelines, Grafana, Snowflake.

8. __Cloud Engineer__
  - February 2020 - August 2021, _Island Labs GmbH_, Germany
  - Kitchen furniture blueprints sometimes contain errors which should be avoided before being sent to construction. As a technical team working with a kitchen provider, we received thousands of kitchen plans on a daily basis. I designed a knowledge graph model to represent the furniture of a kitchen with geometric and graph algorithms to learn and look for errors in it, as well as a pipelined workflow on Azure to process the data. Kitchen blueprints as data are first fed into the workflow by Kafka in real time, these are then validated and sent to a Neo4j cluster by an Azure function. After the kitchen blueprints get ingested and analyzed by Neo4j, the result is sent to the Cosmos DB and returned to the client, in case an error is detected or a warning occurred. Tools: knowledge graph, Kafka, Neo4j, Azure Functions, AKS, Python and .NET.
  
7. __Freelancer__ in a veriety of data projects
  - October 2018 - January 2020, China
  -  Astronomical data can be immense and requires a big data solution to process it. Working together with astronomers, I designed a Spark application for an on premise DWH to process the data and read in from and write out to its different layers. The application includes both batch processing to deal with existent data and streaming to deal with new data coming in. I also optimized the Spark application at different levels which has improved its performance remarkably. Tools: Spark 2.x, Kafka, Hadoop, Java.
  
  
6. __Internship biostatistics and AI__
  - April - September 2018, _Firalis SA_, France
  - The combination of omic data and machine learning / deep learning is one of the cutting-edge areas of biopharma research. In this project where the company aims to get a better understanding of the high-throughput RNA sequencing data of patients undergoing different medical treatments after a myocardial infarction, my machine learning and deep learning algorithms came to help. Tools: Python and R.  
  
5. __Internship psychometry and AI__
  - July - August 2017, _Centre Hospitalier de Rouffach_, France
  - In the psychomotor therapy the diagnosis of schizophrenia had been to that date carried out by the observation and the subjective judgment of medical professionals. With the hope to develop an AI assistant helping physicians make better and more accurate clinical decisions based on more quantitative indicators, I built an application using machine learning and statistical models to predict schizophrenia. Tools: R
  
4. __AI Developer__
  - February - August 2016, _MedVision_, China
  - As a backend developer at MedVision, my role was pivotal in the development of a sophisticated diagnosis assistant system. I focused on designing and implementing user interfaces and software modules in the .NET framework to integrate algorithms developed by machine learning scientists. My work involved using C# for crafting intuitive and responsive desktop applications, ensuring seamless integration of complex AI algorithms for medical diagnostics, particularly for conditions like pulmonary sarcoidosis. My responsibility also included optimizing software performance and ensuring data accuracy through rigorous testing and collaboration with the AI team. Tools: .NET, Windows Forms.
  
3. __Internship Risk Management__
  - November 2015 – February 2016, _Bank of Communications (Luxembourg)_, Luxembourg
  - As a risk analyst I ensured the role of developing statistical tools to monitor credit risk, market risk, liquidity risk and operational risk of the bank. Tools: R and Excel.

2. __Backend Developer__
  - January 2015 - October 2015, _Wanjia Ltd._, China
  - As a Backend Developer at Wanjia, my role centered around contributing to the development of backend systems for online retail platforms. My work primarily involved the implementation of Python-based data processing solutions, essential for efficient inventory management and customer data handling in the online retail sector. A significant part of my responsibilities included working on system architecture, focusing on data security and the optimization of performance. Tools: Python, Django, PostgreSQL, RabbitMQ.

1. __Backend Developer__
  - January 2013 - December 2014, _Shanghai Teso Co._, Luxembourg
  - At Teso, my role as a Backend Developer involved the creation and maintenance of logistics management systems, with a focus on optimizing performance and managing databases effectively. I was responsible for utilizing Java and the Spring Framework to construct robust and scalable services, catering to a dynamic and demanding logistics environment. My work also included the integration of SOAP and RESTful APIs to facilitate seamless communication with various third-party services. Tools: Java, Spring, MySQL, SOAP, RESTful.
   
   
  He holds a Master degree in Data Science from the Université Claude Bernard Lyon 1 and a Bachelor Degree in Mathematics from the Université de Strasbourg.

### Support or Contact

  Interested in him or having nice projects for coorperation? Take a look at [his Github homepage](https://github.com/Alsaxian), write him via [xian.yang@hueninger.com](mailto:xian.yang@hueninger.com) or [ring him](+33695634584). You are also sincerely invited to make suggestions to his Github homepage.
